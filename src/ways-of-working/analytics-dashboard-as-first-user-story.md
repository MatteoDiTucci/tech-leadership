# Analytics dashboard as first user story

## Problem
A new feature goes live, and endless discussions follow about how to measure success.  
At the beginning is just: revenue or conversion rate?
Soon it escalates to complex metrics, customer segments definition, marketing effects, etc.

## Context
When planning a new product initiative, success criteria seem clear.
Usually, the initiative is part of a well-defined business objective with its quantified key results.

However, when building analytics dashboards after the go-live, often two problems arise:
- It is hard to measure the impact of a single feature in isolation
- Some tracking capabilities are missing to measure the success criteria

## Solution
For any product or tech initiative, the first user story is to build the analytics dashboard measuring the success criteria.
This brings the following benefits:
- Hard conversations (e.g. revenue cannibalization) start earlier
- Missing tracking capabilities do not increase scope unexpectedly close to go-live
- No retrofitting success criteria to what is measured or can be measured after go-live

### A/B testing
Sometimes the difficulty of defining the analytics dashboard makes it clear that an A/B test is needed.  
Understanding this close to go-live, or worse after it, can be very costly.

### Human behavior
Despite monetary metrics look very appealing on analytics dashboard, the real success criteria must be related to human behavior.  
Generating revenue is the side effect of changing human behavior, hopefully for the better.

## Notes
- For analytics dashboards we mean something like [Mixpanel](https://mixpanel.com) for product initiatives or [Datadog](https://www.datadoghq.com/) for tech ones